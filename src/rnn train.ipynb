{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3bad0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34770018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a1e3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = np.load('data/TOKENIZEDtrainData.npy')\n",
    "validationData = np.load('data/TOKENIZEDvalidationData.npy')\n",
    "trainLabels = pd.read_parquet('data/y_train.parquet').to_numpy()\n",
    "validationLabels = pd.read_parquet('data/y_test.parquet').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f4dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/dataWithoutComments.parquet')\n",
    "df = df.dropna()\n",
    "x_train, x_test, y_train, y_test = download_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83731295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 979884/979884 [05:54<00:00, 2762.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████| 244971/244971 [01:28<00:00, 2757.42it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('data/ft_train.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for each_text, each_label in tqdm(zip(x_train['code'], y_train['language']), total=len(x_train)):\n",
    "        f.writelines(f'{each_text}\\n')\n",
    "j\n",
    "with open('data/ft_test.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for each_text, each_label in tqdm(zip(x_test['code'], y_test['language']), total=len(x_test)):\n",
    "        f.writelines(f'{each_text}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859de585",
   "metadata": {},
   "source": [
    "# Проверить траблууу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce39bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/tokenizer/without comments\\\\vocab.json',\n",
       " 'model/tokenizer/without comments\\\\merges.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [str(x) for x in Path('data/').glob('*.txt')]\n",
    "\n",
    "# initialize\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "# and train\n",
    "tokenizer.train(files=paths, vocab_size=250000, min_frequency=2,\n",
    "                special_tokens=['<|endoftext|>', '<s>', '<pad>', '</s>', '<unk>', '<mask>'], show_progress=True)\n",
    "\n",
    "tokenizer.save_model('model/tokenizer/without comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af45f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model/tokenizer/without comments\"\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "            vocab = f'{PATH}/vocab.json', \n",
    "            merges= f'{PATH}/merges.txt', \n",
    "            add_prefix_space = True)\n",
    "\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba401ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [''''# syntax: GAWK -f ASCENDING_PRIMES.AWK\n",
    "BEGIN {\n",
    "    start = 1\n",
    "    stop = 23456789\n",
    "    for (i=start; i<=stop; i++) {\n",
    "      if (is_prime(i)) {\n",
    "        primes++\n",
    "        leng = length(i)\n",
    "        flag = 1\n",
    "        for (j=1; j<leng; j++) {\n",
    "          if (substr(i,j,1) >= substr(i,j+1,1)) {\n",
    "            flag = 0\n",
    "            break\n",
    "          }\n",
    "        }\n",
    "        if (flag) {\n",
    "          printf(\"%9d%1s\",i,++count%10?\"\":\"\\n\")\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    printf(\"\\n%d-%d: %d primes, %d ascending primes\\n\",start,stop,primes,count)\n",
    "    exit(0)\n",
    "}\n",
    "function is_prime(n,  d) {\n",
    "    d = 5\n",
    "    if (n < 2) { return(0) }\n",
    "    if (n % 2 == 0) { return(n == 2) }\n",
    "    if (n % 3 == 0) { return(n == 3) }\n",
    "    while (d*d <= n) {\n",
    "      if (n % d == 0) { return(0) }\n",
    "      d += 2\n",
    "      if (n % d == 0) { return(0) }\n",
    "      d += 4\n",
    "    }\n",
    "    return(1)\n",
    "}''', '''// Ascending primes. Nigel Galloway: April 19th., 2022\n",
    "[2;3;5;7]::List.unfold(fun(n,i)->match n with []->None |_->let n=n|>List.map(fun(n,g)->[for n in n.. -1..1->(n-1,i*n+g)])|>List.concat in Some(n|>List.choose(fun(_,n)->if isPrime n then Some n else None),(n|>List.filter(fst>>(<)0),i*10)))([(2,3);(6,7);(8,9)],10)\n",
    "  |>List.concat|>List.sort|>List.iter(printf \"%d \"); printfn \"\"''']\n",
    "enc = tokenizer.encode_batch(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5552cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Encoding(num_tokens=336, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing]),\n",
       " Encoding(num_tokens=168, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_batch(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86cbbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " '# syntax: GAWK -f ASCENDING_PRIMES.AWK\n",
      "BEGIN {\n",
      "    start = 1\n",
      "    stop = 23456789\n",
      "    for (i=start; i<=stop; i++) {\n",
      "      if (is_prime(i)) {\n",
      "        primes++\n",
      "        leng = length(i)\n",
      "        flag = 1\n",
      "        for (j=1; j<leng; j++) {\n",
      "          if (substr(i,j,1) >= substr(i,j+1,1)) {\n",
      "            flag = 0\n",
      "            break\n",
      "          }\n",
      "        }\n",
      "        if (flag) {\n",
      "          printf(\"%9d%1s\",i,++count%10?\"\":\"\n",
      "\")\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    printf(\"\n",
      "%d-%d: %d primes, %d ascending primes\n",
      "\",start,stop,primes,count)\n",
      "    exit(0)\n",
      "}\n",
      "function is_prime(n,  d) {\n",
      "    d = 5\n",
      "    if (n < 2) { return(0) }\n",
      "    if (n % 2 == 0) { return(n == 2) }\n",
      "    if (n % 3 == 0) { return(n == 3) }\n",
      "    while (d*d <= n) {\n",
      "      if (n % d == 0) { return(0) }\n",
      "      d += 2\n",
      "      if (n % d == 0) { return(0) }\n",
      "      d += 4\n",
      "    }\n",
      "    return(1)\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(enc[0].ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c43010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab()['<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd70b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d21b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff4ca814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, inp_voc, emb_size=64, hid_size=128, num_classes=100):\n",
    "        \"\"\"\n",
    "        Базовая модель encoder-decoder архитектуры\n",
    "        \"\"\"\n",
    "        super().__init__() \n",
    "\n",
    "        self.inp_voc = inp_voc\n",
    "        self.hid_size = hid_size\n",
    "        self.eos_ix = self.inp_voc.get_vocab()['<|endoftext|>']\n",
    "        \n",
    "        self.emb_inp = nn.Embedding(inp_voc.get_vocab_size(), emb_size)\n",
    "        self.enc0 = nn.GRU(emb_size, hid_size, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hid_size, num_classes)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        ans = self.encode(inp)\n",
    "        return ans\n",
    "\n",
    "\n",
    "    def encode(self, inp, **flags):\n",
    "        \"\"\"\n",
    "        Считаем скрытое состояние, которое будет начальным для decode\n",
    "        :param inp: матрица входных токенов\n",
    "        :returns: скрытое представление с которого будет начинаться decode\n",
    "        \"\"\"\n",
    "        inp_emb = self.emb_inp(inp)\n",
    "        batch_size = inp.shape[0]\n",
    "        \n",
    "        enc_seq, [last_state_but_not_really] = self.enc0(inp_emb)\n",
    "        # enc_seq: [batch, time, hid_size], last_state: [batch, hid_size]\n",
    "        \n",
    "        # последний токен, не последние на самом деле, так как мы делали pading, чтобы тексты были\n",
    "        # одинакового размер, поэтому подсчитать длину исходного предложения не так уж тривиально\n",
    "        lengths = (inp != self.eos_ix).to(torch.int64).sum(dim=1).clamp_max(inp.shape[1] - 1)\n",
    "        last_state = enc_seq[torch.arange(len(enc_seq)), lengths]\n",
    "        # ^-- shape: [batch_size, hid_size]\n",
    "        \n",
    "        out = self.fc(last_state)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43ace61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layer converts integer sequences to vector sequences\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)#, sparse=True)\n",
    "        \n",
    "        # LSTM layer process the vector sequences \n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers = n_layers,\n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout,\n",
    "                            batch_first=True\n",
    "                           )\n",
    "        \n",
    "        # Dense layer to predict \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        # Prediction activation function\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def forward(self,text, text_lengths):\n",
    "        #print(text.shape, text_lengths.shape)\n",
    "        #text = text.T\n",
    "        #print(text.shape, text_lengths.shape)\n",
    "        embedded = self.embedding(text)\n",
    "        #print(text.shape)\n",
    "        # Thanks to packing, LSTM don't see padding tokens \n",
    "        # and this makes our model better\n",
    "        #print(text_lengths.shape)\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), enforce_sorted=False, batch_first=True)\n",
    "        packed_output, (hidden_state, cell_state) = self.lstm(packed_embedded)\n",
    "        \n",
    "        # Concatenating the final forward and backward hidden states\n",
    "        #print(hidden_state.shape)# 4 64 128\n",
    "        hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n",
    "        \n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        #outputs=self.sigmoid(dense_outputs)\n",
    "        \n",
    "        return dense_outputs#outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517201b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(batch: np.array, tokenizer) -> list:\n",
    "    encoding = tokenizer.encode_batch(batch)\n",
    "    en_train_data = [torch.tensor(e.ids, dtype=torch.long) for e in encoding]\n",
    "    return en_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa699adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fitter(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        opt,\n",
    "        loss,\n",
    "        train_dataloader,\n",
    "        scheduler,\n",
    "        test_dataloader,\n",
    "        batch_size = 128,\n",
    "        sheduler_steps = 10,\n",
    "        n_epochs = 10\n",
    "    ):\n",
    "\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.sheduler_steps = sheduler_steps\n",
    "\n",
    "        self.opt = opt\n",
    "        self.loss = loss\n",
    "        self.scheduler = scheduler\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        \n",
    "        self.model.to(device)\n",
    "        self.metrics = {'train_loss': [], 'dev_ROC-AUC': [],\n",
    "                       'dev_accuracy': [], 'dev_F1': []}\n",
    "\n",
    "    def fit(self):\n",
    "        # Turn on training\n",
    "        self.model.train(True)\n",
    "        \n",
    "        # Fit\n",
    "        for epoch in range(self.n_epochs):\n",
    "            train_loss = 0\n",
    "            i = 0\n",
    "            for (inps, targets) in tqdm(self.train_dataloader, desc='Работаем Братья'):\n",
    "                targets = torch.tensor(targets, device=device)\n",
    "                self.opt.zero_grad()\n",
    "            \n",
    "                pred = self.model(inps.to(device), torch.count_nonzero(inps, dim=1))\n",
    "                loss = self.loss(pred, targets)\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                train_loss += loss.item()\n",
    "                i += 1\n",
    "            \n",
    "            if epoch % self.sheduler_steps == 1:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "             \n",
    "            self.model.eval()\n",
    "            self.metrics['train_loss'] += [train_loss / (i+1)]\n",
    "            preds = np.empty(0, dtype=np.int64)\n",
    "            out_label_ids = np.empty(0, dtype=np.int64)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                i = 0\n",
    "                for (inps, targets) in tqdm(self.test_dataloader, desc='Валидация'):\n",
    "                    \n",
    "                    targets = torch.tensor(targets, device=device)\n",
    "                    \n",
    "                    pred =  self.model(inps.to(device), torch.count_nonzero(inps, dim=1))\n",
    "                    pred = F.softmax(pred, dim=1).detach().argmax(dim=1).cpu().numpy()\n",
    "                    preds = np.append(preds, pred, axis=0)\n",
    "                    out_label_ids = np.append(out_label_ids, targets.argmax(dim=1).cpu(), axis=0)\n",
    "                    i += 1\n",
    "                    \n",
    "            self.metrics['dev_accuracy'] += [simple_accuracy(preds, out_label_ids)]\n",
    "            self.metrics['dev_F1'] += [f1_score(y_true=out_label_ids, y_pred=preds, average=\"macro\")]\n",
    "\n",
    "            if ((len(self.metrics['dev_accuracy']) > 2 and self.metrics['dev_accuracy'][-1] > self.metrics['dev_accuracy'][-2])\n",
    "               or\n",
    "                len(self.metrics['dev_accuracy']) == 1\n",
    "               ):\n",
    "                torch.save(self.model, 'model/rnn.pt')\n",
    "            \n",
    "            clear_output(wait=True) \n",
    "            plt.figure(figsize=(10, 5))\n",
    "            \n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"Train Loss\")\n",
    "            plt.grid()\n",
    "            plt.plot(self.metrics['train_loss'])\n",
    "            \n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"Accuracy\")\n",
    "            plt.plot(self.metrics['dev_accuracy'], color=\"orange\")\n",
    "            plt.grid()\n",
    "            \n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"F1\")\n",
    "            plt.plot(self.metrics['dev_F1'], color=\"orange\")\n",
    "            plt.grid()\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "            self.model.train(True)\n",
    "            \n",
    "        # Turn off training\n",
    "        self.model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a5bbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    def __init__(self, inp, target):\n",
    "        self.inp = inp\n",
    "        self.target = target\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inp)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inp[idx], int(self.target[idx])\n",
    "\n",
    "num_labels = len(np.unique(trainLabels))\n",
    "\n",
    "def batch_collate_fn(batch):\n",
    "    inps = [item[0] for item in batch]\n",
    "    labels = np.array([item[1] for item in batch])\n",
    "    out = np.zeros((len(labels), num_labels))\n",
    "    out[np.arange(len(labels)), labels] = 1\n",
    "    return torch.tensor(inps, dtype=torch.long), out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3205fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dict = {x: y for y, x in enumerate(np.unique(trainLabels))}\n",
    "dec_dict = {y: x for y, x in enumerate(np.unique(trainLabels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5928ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dict = [\n",
    "  'TGLANG_LANGUAGE_OTHER',\n",
    "  'TGLANG_LANGUAGE_1S_ENTERPRISE',\n",
    "  'TGLANG_LANGUAGE_ABAP',\n",
    "  'TGLANG_LANGUAGE_ACTIONSCRIPT',\n",
    "  'TGLANG_LANGUAGE_ADA',\n",
    "  'TGLANG_LANGUAGE_APACHE_GROOVY',\n",
    "  'TGLANG_LANGUAGE_APEX',\n",
    "  'TGLANG_LANGUAGE_APPLESCRIPT',\n",
    "  'TGLANG_LANGUAGE_ASP',\n",
    "  'TGLANG_LANGUAGE_ASSEMBLY',\n",
    "  'TGLANG_LANGUAGE_AUTOHOTKEY',\n",
    "  'TGLANG_LANGUAGE_AWK',\n",
    "  'TGLANG_LANGUAGE_BASIC',\n",
    "  'TGLANG_LANGUAGE_BATCH',\n",
    "  'TGLANG_LANGUAGE_BISON',\n",
    "  'TGLANG_LANGUAGE_C',\n",
    "  'TGLANG_LANGUAGE_CLOJURE',\n",
    "  'TGLANG_LANGUAGE_CMAKE',\n",
    "  'TGLANG_LANGUAGE_COBOL',\n",
    "  'TGLANG_LANGUAGE_COFFESCRIPT',\n",
    "  'TGLANG_LANGUAGE_COMMON_LISP',\n",
    "  'TGLANG_LANGUAGE_CPLUSPLUS',\n",
    "  'TGLANG_LANGUAGE_CRYSTAL',\n",
    "  'TGLANG_LANGUAGE_CSHARP',\n",
    "  'TGLANG_LANGUAGE_CSS',\n",
    "  'TGLANG_LANGUAGE_CSV',\n",
    "  'TGLANG_LANGUAGE_D',\n",
    "  'TGLANG_LANGUAGE_DART',\n",
    "  'TGLANG_LANGUAGE_DELPHI',\n",
    "  'TGLANG_LANGUAGE_DOCKER',\n",
    "  'TGLANG_LANGUAGE_ELIXIR',\n",
    "  'TGLANG_LANGUAGE_ELM',\n",
    "  'TGLANG_LANGUAGE_ERLANG',\n",
    "  'TGLANG_LANGUAGE_FIFT',\n",
    "  'TGLANG_LANGUAGE_FORTH',\n",
    "  'TGLANG_LANGUAGE_FORTRAN',\n",
    "  'TGLANG_LANGUAGE_FSHARP',\n",
    "  'TGLANG_LANGUAGE_FUNC',\n",
    "  'TGLANG_LANGUAGE_GAMS',\n",
    "  'TGLANG_LANGUAGE_GO',\n",
    "  'TGLANG_LANGUAGE_GRADLE',\n",
    "  'TGLANG_LANGUAGE_GRAPHQL',\n",
    "  'TGLANG_LANGUAGE_HACK',\n",
    "  'TGLANG_LANGUAGE_HASKELL',\n",
    "  'TGLANG_LANGUAGE_HTML',\n",
    "  'TGLANG_LANGUAGE_ICON',\n",
    "  'TGLANG_LANGUAGE_IDL',\n",
    "  'TGLANG_LANGUAGE_INI',\n",
    "  'TGLANG_LANGUAGE_JAVA',\n",
    "  'TGLANG_LANGUAGE_JAVASCRIPT',\n",
    "  'TGLANG_LANGUAGE_JSON',\n",
    "  'TGLANG_LANGUAGE_JULIA',\n",
    "  'TGLANG_LANGUAGE_KEYMAN',\n",
    "  'TGLANG_LANGUAGE_KOTLIN',\n",
    "  'TGLANG_LANGUAGE_LATEX',\n",
    "  'TGLANG_LANGUAGE_LISP',\n",
    "  'TGLANG_LANGUAGE_LOGO',\n",
    "  'TGLANG_LANGUAGE_LUA',\n",
    "  'TGLANG_LANGUAGE_MAKEFILE',\n",
    "  'TGLANG_LANGUAGE_MARKDOWN',\n",
    "  'TGLANG_LANGUAGE_MATLAB',\n",
    "  'TGLANG_LANGUAGE_NGINX',\n",
    "  'TGLANG_LANGUAGE_NIM',\n",
    "  'TGLANG_LANGUAGE_OBJECTIVE_C',\n",
    "  'TGLANG_LANGUAGE_OCAML',\n",
    "  'TGLANG_LANGUAGE_OPENEDGE_ABL',\n",
    "  'TGLANG_LANGUAGE_PASCAL',\n",
    "  'TGLANG_LANGUAGE_PERL',\n",
    "  'TGLANG_LANGUAGE_PHP',\n",
    "  'TGLANG_LANGUAGE_PL_SQL',\n",
    "  'TGLANG_LANGUAGE_POWERSHELL',\n",
    "  'TGLANG_LANGUAGE_PROLOG',\n",
    "  'TGLANG_LANGUAGE_PROTOBUF',\n",
    "  'TGLANG_LANGUAGE_PYTHON',\n",
    "  'TGLANG_LANGUAGE_QML',\n",
    "  'TGLANG_LANGUAGE_R',\n",
    "  'TGLANG_LANGUAGE_RAKU',\n",
    "  'TGLANG_LANGUAGE_REGEX',\n",
    "  'TGLANG_LANGUAGE_RUBY',\n",
    "  'TGLANG_LANGUAGE_RUST',\n",
    "  'TGLANG_LANGUAGE_SAS',\n",
    "  'TGLANG_LANGUAGE_SCALA',\n",
    "  'TGLANG_LANGUAGE_SCHEME',\n",
    "  'TGLANG_LANGUAGE_SHELL',\n",
    "  'TGLANG_LANGUAGE_SMALLTALK',\n",
    "  'TGLANG_LANGUAGE_SOLIDITY',\n",
    "  'TGLANG_LANGUAGE_SQL',\n",
    "  'TGLANG_LANGUAGE_SWIFT',\n",
    "  'TGLANG_LANGUAGE_TCL',\n",
    "  'TGLANG_LANGUAGE_TEXTILE',\n",
    "  'TGLANG_LANGUAGE_TL',\n",
    "  'TGLANG_LANGUAGE_TYPESCRIPT',\n",
    "  'TGLANG_LANGUAGE_UNREALSCRIPT',\n",
    "  'TGLANG_LANGUAGE_VALA',\n",
    "  'TGLANG_LANGUAGE_VBSCRIPT',\n",
    "  'TGLANG_LANGUAGE_VERILOG',\n",
    "  'TGLANG_LANGUAGE_VISUAL_BASIC',\n",
    "  'TGLANG_LANGUAGE_WOLFRAM',\n",
    "  'TGLANG_LANGUAGE_XML',\n",
    "  'TGLANG_LANGUAGE_YAML']\n",
    "\n",
    "enc_dict = {key: i for i, key in enumerate(enc_dict)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caea01f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SIZE_OF_VOCAB = tokenizer.get_vocab_size()\n",
    "EMBEDDING_DIM = 128\n",
    "NUM_HIDDEN_NODES = 64\n",
    "NUM_OUTPUT_NODES = len(enc_dict)\n",
    "NUM_LAYERS = 2\n",
    "BIDIRECTION = True\n",
    "DROPOUT = 0.2\n",
    "batch_size = 64\n",
    "\n",
    "model = LSTMNet(SIZE_OF_VOCAB,\n",
    "                EMBEDDING_DIM,\n",
    "                NUM_HIDDEN_NODES,\n",
    "                NUM_OUTPUT_NODES,\n",
    "                NUM_LAYERS,\n",
    "                BIDIRECTION,\n",
    "                DROPOUT\n",
    "               ).to(device)\n",
    "\n",
    "# model = BaseModel(tokenizer).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = ExponentialLR(opt, gamma=0.9)\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(trainData, np.array(list(map(enc_dict.get, trainLabels.T[0]))))\n",
    "test_dataset = MyDataset(validationData, np.array(list(map(enc_dict.get, validationLabels.T[0]))))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              collate_fn=batch_collate_fn, shuffle=True, drop_last=True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                             collate_fn=batch_collate_fn, shuffle=False,\n",
    "                              pin_memory=True)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "sheduler_steps = 1\n",
    "epochs = 5\n",
    "\n",
    "fitter =  Fitter(\n",
    "                model,\n",
    "                opt,\n",
    "                loss,\n",
    "                train_dataloader,\n",
    "                scheduler,\n",
    "                test_dataloader,\n",
    "                batch_size = batch_size,\n",
    "                sheduler_steps = sheduler_steps,\n",
    "                n_epochs = epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f4bb6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.4400647917949601],\n",
       " 'dev_ROC-AUC': [],\n",
       " 'dev_accuracy': [0.9705801911246638],\n",
       " 'dev_F1': [0.8046836725393447]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitter.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ef71e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Работаем Братья:  31%|██████████▏                      | 4730/15310 [11:22<25:26,  6.93it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fitter\u001b[38;5;241m.\u001b[39mfit()\n",
      "Cell \u001b[1;32mIn[6], line 42\u001b[0m, in \u001b[0;36mFitter.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(targets, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 42\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inps\u001b[38;5;241m.\u001b[39mto(device), torch\u001b[38;5;241m.\u001b[39mcount_nonzero(inps, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(pred, targets)\n\u001b[0;32m     44\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m, in \u001b[0;36mLSTMNet.forward\u001b[1;34m(self, text, text_lengths)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#print(text.shape)\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Thanks to packing, LSTM don't see padding tokens \u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# and this makes our model better\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#print(text_lengths.shape)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m packed_embedded \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(embedded, text_lengths\u001b[38;5;241m.\u001b[39mcpu(), enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 37\u001b[0m packed_output, (hidden_state, cell_state) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(packed_embedded)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Concatenating the final forward and backward hidden states\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#print(hidden_state.shape)# 4 64 128\u001b[39;00m\n\u001b[0;32m     41\u001b[0m hidden \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((hidden_state[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,:,:], hidden_state[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:,:]), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:882\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    879\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    880\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n\u001b[0;32m    884\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    885\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fitter.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2130c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
